{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Loading data functions\n",
    "'''\n",
    "PIXELS = 100\n",
    "imageSize = PIXELS * PIXELS\n",
    "num_features = imageSize \n",
    "\n",
    "def load_train_cv(encoder):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    print('Read train images')\n",
    "    #Read train ids\n",
    "    with open('id_train.csv', 'rb') as csvfile:\n",
    "        trainreader = csv.reader(csvfile, delimiter=',')\n",
    "        next(trainreader)\n",
    "        for row in trainreader:\n",
    "            #print(row[0])\n",
    "            file_name = os.path.join('input', row[0] + '.jpg')\n",
    "            img = cv2.imread(file_name,0)\n",
    "            img = cv2.resize(img, (PIXELS, PIXELS))\n",
    "            #img = img.transpose(2, 0, 1)\n",
    "            img = np.reshape(img, (1, num_features))\n",
    "            X_train.append(img)\n",
    "            y_train.append(row[1])\n",
    "    #print X_train.shape\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train).astype('int32')\n",
    "\n",
    "    #y_train = encoder.fit_transform(y_train).astype('int32')\n",
    "\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3)\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], num_features).astype('float32') / 255.\n",
    "    X_test = X_test.reshape(X_test.shape[0], num_features).astype('float32') / 255.\n",
    "    \n",
    "    #X_train = X_train.astype('float32') / 255.\n",
    "    #X_test = X_test.astype('float32') / 255.\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, encoder\n",
    "\n",
    "def load_test():\n",
    "    print('Read test images')\n",
    "    X_test = []\n",
    "    X_test_id=[]\n",
    "    with open('sample_submission4.csv', 'rb') as csvfile:\n",
    "        testreader = csv.reader(csvfile, delimiter=',')\n",
    "        next(testreader)\n",
    "        for row in testreader:\n",
    "            #print('Load folder c{}'.format(j))\n",
    "            file_name = os.path.join('input', row[0] + '.jpg')\n",
    "            img = cv2.imread(file_name,0)\n",
    "            img = cv2.resize(img, (PIXELS, PIXELS))\n",
    "            #img = img.transpose(2, 0, 1)\n",
    "            img = np.reshape(img, (1, num_features))\n",
    "            X_test.append(img)\n",
    "            X_test_id.append(row[0])\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    X_test_id = np.array(X_test_id)\n",
    "\n",
    "    X_test = X_test.reshape(X_test.shape[0],num_features ).astype('float32') / 255.\n",
    "\n",
    "    return X_test, X_test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train images\n",
      "('Train shape:', (5600L, 10000L), 'Dev (valid) shape:', (2400L, 10000L))\n",
      "('Train shape:', (5600L,), 'Dev (valid) shape:', (2400L,))\n",
      "Read test images\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "load training data and test data \n",
    "'''\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# load the training and validation data sets\n",
    "train_X, train_y, valid_X, valid_y, encoder = load_train_cv(encoder)\n",
    "print('Train shape:', train_X.shape, 'Dev (valid) shape:', valid_X.shape)\n",
    "print('Train shape:', train_y.shape, 'Dev (valid) shape:', valid_y.shape)\n",
    "\n",
    "# load data\n",
    "X_test, X_test_id = load_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-value:   1 total: 2400  correct: 1220  accuracy: 0.51\n",
      "For K=1, precision, recall and f1-score for all digits shown below\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.65      0.66      1073\n",
      "          2       0.52      0.47      0.49       621\n",
      "          3       0.25      0.31      0.28       198\n",
      "          4       0.30      0.33      0.32       508\n",
      "\n",
      "avg / total       0.52      0.51      0.51      2400\n",
      "\n",
      "K-value:   3 total: 2400  correct: 1315  accuracy: 0.55\n",
      "K-value:   5 total: 2400  correct: 1344  accuracy: 0.56\n",
      "K-value:   7 total: 2400  correct: 1388  accuracy: 0.58\n",
      "K-value:   9 total: 2400  correct: 1376  accuracy: 0.57\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "KNN\n",
    "'''\n",
    "def knn(k_values):\n",
    "\n",
    "    for i in range(0,len(k_values)):\n",
    "        correct, total = 0, 0\n",
    "        knc = KNeighborsClassifier(n_neighbors=k_values[i])\n",
    "        knc.fit(train_X,train_y)\n",
    "        preds = knc.predict(valid_X)\n",
    "        cfm = confusion_matrix(preds,valid_y)\n",
    "        #confusion matrix and print\n",
    "        #print cfm\n",
    "        for pred, label in zip(preds, valid_y):\n",
    "            if pred == label: correct += 1\n",
    "            total += 1\n",
    "        print 'K-value: %3d total: %3d  correct: %3d  accuracy: %3.2f' %(k_values[i],total, correct, 1.0*correct/total)\n",
    "        if k_values[i]==1:\n",
    "            kncr = classification_report(preds,valid_y)\n",
    "            print \"For K=1, precision, recall and f1-score for all digits shown below\"\n",
    "            print kncr\n",
    "\n",
    "    \n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "knn(k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e16b5669d289>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mblurred_valid_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianBlur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mblurred_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianBlur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-e16b5669d289>\u001b[0m in \u001b[0;36mGaussianBlur\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                         \u001b[1;31m#Apply Blurring weighted average\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                         \u001b[0mblur\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mPIXELS\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#weighted average\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                         \u001b[0mblur\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mPIXELS\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#No weighting for border cells\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Let's go with n_neighbors=7\n",
    "\n",
    "#Apply Gaussian Blurring\n",
    "\n",
    "def GaussianBlur(data):\n",
    "    \n",
    "    blur = np.zeros(data.shape)\n",
    "    for k in range(0,len(data)):\n",
    "        data_mat = np.ndarray.reshape(data[k],(-1,PIXELS))\n",
    "\n",
    "        for i in range(0,PIXELS):\n",
    "            for j in range(0,PIXELS):\n",
    "                if data_mat[i][j] >0 :\n",
    "                    try:\n",
    "                        \n",
    "                        #Gather values from the 8 adjacent cells\n",
    "                        val = np.array([data_mat[i-1][j-1],data_mat[i-1][j],data_mat[i-1][j+1] \\\n",
    "                                   ,data_mat[i][j-1],data_mat[i][j],data_mat[i][j+1] \\\n",
    "                                   ,data_mat[i+1][j-1],data_mat[i+1][j],data_mat[i+1][j+1]])\n",
    "                        \n",
    "                        #Compute standard deviation\n",
    "                        stdev = np.std(val)\n",
    "                        if stdev==0:\n",
    "                            blur[k:k+1][0][PIXELS*i+j] = data_mat[i][j] #No weighting if all neighbors have same value\n",
    "                            continue                           \n",
    "                        \n",
    "                        #Copmute neighbors weights and self weights using gaussian distance\n",
    "                        neighbor_weight = (1/pow(2*np.pi*pow(stdev,2),0.5))*np.exp(-1/(2*pow(stdev,2)))\n",
    "                        self_weight = (1/pow(2*np.pi*pow(stdev,2),0.5))*np.exp(0)\n",
    "                        weights = [neighbor_weight,neighbor_weight,neighbor_weight \\\n",
    "                                   ,neighbor_weight,self_weight,neighbor_weight \\\n",
    "                                  ,neighbor_weight,neighbor_weight,neighbor_weight]\n",
    "                        \n",
    "                        #Apply Blurring weighted average\n",
    "                        blur[k:k+1][0][PIXELS*i+j] = np.sum(val * weights) / sum(val) #weighted average\n",
    "                    except IndexError:\n",
    "                        blur[k:k+1][0][PIXELS*i+j] = data_mat[i][j] #No weighting for border cells\n",
    "    \n",
    "    return blur\n",
    "\n",
    "blurred_valid_data = GaussianBlur(valid_X)\n",
    "blurred_train_data = GaussianBlur(train_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-value:   5 total: 2400  correct: 565  accuracy: 0.24\n",
      "K-value:   5 total: 2400  correct: 513  accuracy: 0.21\n",
      "K-value:   5 total: 2400  correct: 1278  accuracy: 0.53\n"
     ]
    }
   ],
   "source": [
    "#Apply Blurring to only train and not validation\n",
    "correct, total = 0, 0\n",
    "knc = KNeighborsClassifier(n_neighbors=7)\n",
    "knc.fit(blurred_train_data,train_y)\n",
    "preds = knc.predict(valid_X)\n",
    "for pred, label in zip(preds, valid_y):\n",
    "    if pred == label: correct += 1\n",
    "    total += 1\n",
    "print 'K-value: %3d total: %3d  correct: %3d  accuracy: %3.2f' %(5,total, correct, 1.0*correct/total)\n",
    "\n",
    "#Apply Blurring to only validation and not train\n",
    "correct, total = 0, 0\n",
    "knc = KNeighborsClassifier(n_neighbors=7)\n",
    "knc.fit(train_X,train_y)\n",
    "preds = knc.predict(blurred_valid_data)\n",
    "for pred, label in zip(preds, valid_y):\n",
    "    if pred == label: correct += 1\n",
    "    total += 1\n",
    "print 'K-value: %3d total: %3d  correct: %3d  accuracy: %3.2f' %(5,total, correct, 1.0*correct/total)\n",
    "\n",
    "#Apply Blurring to both\n",
    "correct, total = 0, 0\n",
    "knc = KNeighborsClassifier(n_neighbors=7)\n",
    "knc.fit(blurred_train_data,train_y)\n",
    "preds = knc.predict(blurred_valid_data)\n",
    "for pred, label in zip(preds, valid_y):\n",
    "    if pred == label: correct += 1\n",
    "    total += 1\n",
    "print 'K-value: %3d total: %3d  correct: %3d  accuracy: %3.2f' %(5,total, correct, 1.0*correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data model accuracy 0.420833333333\n",
      "BernoulliNB(alpha=0.001, binarize=0.0, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Let's try Gaussian Naive Bayes Classifier\n",
    "'''\n",
    "def alphaNB(alphas):\n",
    "\n",
    "    #Grid Search\n",
    "    clf = GridSearchCV(BernoulliNB(), alphas)\n",
    "    clf.fit(train_X, train_y)\n",
    "    preds = clf.predict(valid_X)\n",
    "    \n",
    "    #Check Accuracy\n",
    "    correct,total=0,0\n",
    "    for pred, label in zip(preds, valid_y):\n",
    "        if pred == label: correct += 1\n",
    "        total += 1\n",
    "    accuracy = 1.0*correct/total\n",
    "    print \"data model accuracy %s\" % accuracy\n",
    "    print clf.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "#alphas = {'alpha': [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "alphas = {'alpha': [ 0.0001, 0.001, 0.01, 0.1]}\n",
    "nb = alphaNB(alphas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Naive Bayes performing poorly at alpha=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(pred) <= 0.5000000000000    total =   2    accuracy = 0.500\n",
      "p(pred) <= 0.9000000000000    total =   8    accuracy = 0.500\n",
      "p(pred) <= 0.9990000000000    total =   0    accuracy = 0.000\n",
      "p(pred) <= 0.9999900000000    total =   0    accuracy = 0.000\n",
      "p(pred) <= 0.9999999000000    total =   0    accuracy = 0.000\n",
      "p(pred) <= 0.9999999990000    total =   0    accuracy = 0.000\n",
      "p(pred) <= 0.9999999999900    total =   0    accuracy = 0.000\n",
      "p(pred) <= 0.9999999999999    total =   0    accuracy = 0.000\n",
      "p(pred) <= 1.0000000000000    total = 2390    accuracy = 0.440\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Check calibration level for Gaussian NB\n",
    "'''\n",
    "\n",
    "def NB_Calibration(buckets, correct, total):\n",
    "    \n",
    "    \n",
    "    #Fit model and obtian posterior probabilities\n",
    "    clf = BernoulliNB(alpha=0.01)\n",
    "    clf.fit(train_X,train_y)\n",
    "    prob = np.exp(clf.feature_log_prob_)\n",
    "    preds = clf.predict(valid_X)\n",
    "    preds_prob = clf.predict_proba(valid_X)\n",
    "    \n",
    "    #Bucket the posterior probs and check for accuracy\n",
    "    for pred,label,posteriors in zip(preds, valid_y, preds_prob):\n",
    "        max_prob = np.max(posteriors)\n",
    "        bucket_index = np.digitize(max_prob, buckets) #based on max_prob\n",
    "        if pred == label: correct[bucket_index-1] += 1.0\n",
    "        total[bucket_index-1] += 1.0\n",
    "\n",
    "\n",
    "buckets = [0.5, 0.9, 0.999, 0.99999, 0.9999999, 0.999999999, 0.99999999999, 0.9999999999999, 1.0]\n",
    "correct = [0 for i in buckets]\n",
    "total = [0 for i in buckets]\n",
    "\n",
    "NB_Calibration(buckets, correct, total)\n",
    "\n",
    "for i in range(len(buckets)):\n",
    "    accuracy = 0.0\n",
    "    if (total[i] > 0): accuracy = correct[i] / total[i]\n",
    "    print 'p(pred) <= %.13f    total = %3d    accuracy = %.3f' %(buckets[i], total[i], accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB classifier is weakly claibrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Submission\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Create Submissions - Best model so far KNN (n=7)\n",
    "'''\n",
    "\n",
    "import csv\n",
    "\n",
    "#make predictions\n",
    "print('Making predictions')\n",
    "knc = KNeighborsClassifier(n_neighbors=7)\n",
    "knc.fit(train_X,train_y)\n",
    "preds = knc.predict(X_test)\n",
    "\n",
    "def create_submission(predictions, test_id):\n",
    "     with open('submit.csv', 'wb') as mycsvfile:\n",
    "            thedatawriter = csv.writer(mycsvfile)\n",
    "            thedatawriter.writerow(['Id','label'])\n",
    "            for pred,testid  in zip(predictions,test_id):\n",
    "                out = [testid,pred]\n",
    "                thedatawriter.writerow(out)\n",
    "    \n",
    "\n",
    "print('Creating Submission')\n",
    "create_submission(preds, X_test_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
