{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import lasagne\n",
    "from lasagne import layers\n",
    "from lasagne.layers import helper\n",
    "from lasagne.updates import adam\n",
    "from lasagne.nonlinearities import rectify, softmax\n",
    "from lasagne.layers import InputLayer, DenseLayer, DropoutLayer, helper\n",
    "from lasagne.layers import InputLayer, MaxPool2DLayer, DenseLayer, DropoutLayer, helper\n",
    "#from lasagne.layers import Conv2DLayer as ConvLayer\n",
    "\n",
    "try:\n",
    "    from lasagne.layers.cuda_convnet import Conv2DLayer\n",
    "    from lasagne.layers.cuda_convnet import MaxPool2DLayer\n",
    "except ImportError:\n",
    "    Conv2DLayer = layers.Conv2DLayer\n",
    "    MaxPool2DLayer = layers.MaxPool2DLayer\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "\n",
    "\n",
    "#try:\n",
    "#   theano.config.device = 'gpu'\n",
    "#except:\n",
    "    #pass # its already set\n",
    "#theano.config.device = 'cpu'\n",
    "theano.config.floatX = 'float64'\n",
    "theano.config.blas.ldflags='-LC:\\\\openblas -lopenblas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Loading data functions\n",
    "'''\n",
    "PIXELS = 24\n",
    "imageSize = PIXELS * PIXELS\n",
    "num_features = imageSize \n",
    "\n",
    "def load_train_cv(encoder):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    print('Read train images')\n",
    "    with open('id_train.csv', 'rb') as csvfile:\n",
    "        trainreader = csv.reader(csvfile, delimiter=',')\n",
    "        next(trainreader)\n",
    "        for row in trainreader:\n",
    "            file_name = os.path.join('input', row[0] + '.jpg')\n",
    "            img = cv2.imread(file_name,0)\n",
    "            img = cv2.resize(img, (PIXELS, PIXELS))\n",
    "            #img = img.transpose(2, 0, 1)\n",
    "            img = np.reshape(img, (1, num_features))\n",
    "            X_train.append(img)\n",
    "            y_train.append(row[1])\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)#.astype('int32')\n",
    "\n",
    "    y_train = encoder.fit_transform(y_train).astype('int32')\n",
    "\n",
    "    X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, PIXELS, PIXELS).astype('float32') / 255.\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, PIXELS, PIXELS).astype('float32') / 255.\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, encoder\n",
    "\n",
    "def load_test():\n",
    "    print('Read test images')\n",
    "    X_test = []\n",
    "    X_test_id = []\n",
    "    with open('sample_submission4.csv', 'rb') as csvfile:\n",
    "        testreader = csv.reader(csvfile, delimiter=',')\n",
    "        next(testreader)\n",
    "        for row in testreader:\n",
    "            file_name = os.path.join('input', row[0] + '.jpg')\n",
    "            img = cv2.imread(file_name,0)\n",
    "            img = cv2.resize(img, (PIXELS, PIXELS))\n",
    "            #img = img.transpose(2, 0, 1)\n",
    "            img = np.reshape(img, (1, num_features))\n",
    "            X_test.append(img)\n",
    "            X_test_id.append(row[0])\n",
    "\n",
    "    X_test = np.array(X_test)\n",
    "    X_test_id = np.array(X_test_id)\n",
    "\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, PIXELS, PIXELS).astype('float32') / 255.\n",
    "\n",
    "    return X_test, X_test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train images\n",
      "('Train shape:', (6400L, 1L, 24L, 24L), 'Dev (valid) shape:', (1600L, 1L, 24L, 24L))\n",
      "('Train shape:', (6400L,), 'Dev (valid) shape:', (1600L,))\n",
      "Read test images\n",
      "('Test shape:', (13999L, 1L, 24L, 24L), 'Test ID shape:', (13999L,))\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "load training data and test data \n",
    "'''\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# load the training and validation data sets\n",
    "train_X, train_y, valid_X, valid_y, encoder = load_train_cv(encoder)\n",
    "print('Train shape:', train_X.shape, 'Dev (valid) shape:', valid_X.shape)\n",
    "print('Train shape:', train_y.shape, 'Dev (valid) shape:', valid_y.shape)\n",
    "\n",
    "# load data\n",
    "X_test, X_test_id = load_test()\n",
    "print('Test shape:', X_test.shape, 'Test ID shape:', X_test_id.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1 2777]\n",
      " [   2 1498]\n",
      " [   3  678]\n",
      " [   4 1447]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAEKCAYAAAAy4ujqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d3b9e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot an example image with its label\n",
    "#print train_X[:1]\n",
    "unique, counts = np.unique(train_y, return_counts=True)\n",
    "print np.asarray((unique, counts)).T\n",
    "\n",
    "plt.imshow(train_X[527][0], interpolation='nearest', cmap=plt.cm.gray)\n",
    "plt.title(\"Label: {}\".format(train_y[527]))\n",
    "plt.gca().set_axis_off()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Lasagne Model ZFTurboNet and Batch Iterator\n",
    "'''\n",
    "def ZFTurboNet(input_var=None):\n",
    "    l_in = InputLayer(shape=(None, 1, PIXELS, PIXELS), input_var=input_var)\n",
    "\n",
    "    l_conv = ConvLayer(l_in, num_filters=8, filter_size=(3,3), pad=1, nonlinearity=rectify)\n",
    "    l_pool1 = MaxPool2DLayer(l_conv, pool_size=2) # feature maps 12x12\n",
    "    l_convb = ConvLayer(l_pool1, num_filters=8, filter_size=(3,3), pad=1, nonlinearity=rectify)\n",
    "    l_pool2 = MaxPool2DLayer(l_convb, pool_size=2) # feature maps 12x12\n",
    "\n",
    "    l_dropout1 = DropoutLayer(l_pool2, p=0.25)\n",
    "    l_hidden = DenseLayer(l_dropout1, num_units=128, nonlinearity=rectify)\n",
    "    l_dropout2 = DropoutLayer(l_hidden, p=0.5)\n",
    "\n",
    "    l_out = DenseLayer(l_dropout2, # The number of units in the softmas output layer is the number of classes.\n",
    "                       num_units=4, nonlinearity=softmax)\n",
    "\n",
    "    return l_out\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize):\n",
    "    assert len(inputs) == len(targets)\n",
    "    indices = np.arange(len(inputs))\n",
    "    np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set up all theano functions\n",
    "\"\"\"\n",
    "BATCHSIZE = 50\n",
    "LR = 0.001\n",
    "ITERS = 5\n",
    "\n",
    "theano.config.optimizer = 'None'\n",
    "\n",
    "X = T.tensor4('X')\n",
    "Y = T.ivector('y')\n",
    "\n",
    "# set up theano functions to generate output by feeding data through network, any test outputs should be deterministic\n",
    "output_layer = ZFTurboNet(X)\n",
    "output_train = lasagne.layers.get_output(output_layer)\n",
    "output_test = lasagne.layers.get_output(output_layer, deterministic=True)\n",
    "\n",
    "# set up the loss that we aim to minimize, when using cat cross entropy our Y should be ints not one-hot\n",
    "loss = lasagne.objectives.categorical_crossentropy(output_train, Y)\n",
    "loss = loss.mean()\n",
    "\n",
    "# set up loss functions for validation dataset\n",
    "valid_loss = lasagne.objectives.categorical_crossentropy(output_test, Y)\n",
    "valid_loss = valid_loss.mean()\n",
    "\n",
    "valid_acc = T.mean(T.eq(T.argmax(output_test, axis=1), Y), dtype=theano.config.floatX)\n",
    "\n",
    "# get parameters from network and set up sgd with nesterov momentum to update parameters\n",
    "params = lasagne.layers.get_all_params(output_layer, trainable=True)\n",
    "updates = adam(loss, params, learning_rate=LR)\n",
    "\n",
    "# set up training and prediction functions\n",
    "train_fn = theano.function(inputs=[X,Y], outputs=loss, updates=updates)\n",
    "valid_fn = theano.function(inputs=[X,Y], outputs=[valid_loss, valid_acc])\n",
    "\n",
    "# set up prediction function\n",
    "predict_proba = theano.function(inputs=[X], outputs=output_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('iter:', 0, '| TL:', 1.268, '| VL:', 1.182, '| Vacc:', 0.47299999, '| Ratio:', 1.0700001, '| Time:', 34.0)\n",
      "('iter:', 1, '| TL:', 1.126, '| VL:', 1.034, '| Vacc:', 0.60299999, '| Ratio:', 1.09, '| Time:', 30.600000000000001)\n",
      "('iter:', 2, '| TL:', 1.018, '| VL:', 0.95999998, '| Vacc:', 0.60900003, '| Ratio:', 1.0599999, '| Time:', 28.199999999999999)\n",
      "('iter:', 3, '| TL:', 0.963, '| VL:', 0.92799997, '| Vacc:', 0.62099999, '| Ratio:', 1.04, '| Time:', 28.300000000000001)\n",
      "('iter:', 4, '| TL:', 0.93699998, '| VL:', 0.898, '| Vacc:', 0.64099997, '| Ratio:', 1.04, '| Time:', 28.399999999999999)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "start training\n",
    "'''\n",
    "\n",
    "# loop over training functions for however many iterations, print information while training\n",
    "try:\n",
    "    for epoch in range(ITERS):\n",
    "        # do the training\n",
    "        start = time.time()\n",
    "        # training batches\n",
    "        train_loss = []\n",
    "        for batch in iterate_minibatches(train_X, train_y, BATCHSIZE):\n",
    "            inputs, targets = batch\n",
    "            train_loss.append(train_fn(inputs, targets))\n",
    "        train_loss = np.mean(train_loss)\n",
    "        # validation batches\n",
    "        valid_loss = []\n",
    "        valid_acc = []\n",
    "        for batch in iterate_minibatches(valid_X, valid_y, BATCHSIZE):\n",
    "            inputs, targets = batch\n",
    "            valid_eval = valid_fn(inputs, targets)\n",
    "            valid_loss.append(valid_eval[0])\n",
    "            valid_acc.append(valid_eval[1])\n",
    "        valid_loss = np.mean(valid_loss)\n",
    "        valid_acc = np.mean(valid_acc)\n",
    "        # get ratio of TL to VL\n",
    "        ratio = train_loss / valid_loss\n",
    "        end = time.time() - start\n",
    "        # print training details\n",
    "        print('iter:', epoch, '| TL:', np.round(train_loss,decimals=3), '| VL:', np.round(valid_loss, decimals=3), \\\n",
    "              '| Vacc:', np.round(valid_acc, decimals=3), '| Ratio:', np.round(ratio, decimals=2), '| Time:', \\\n",
    "              np.round(end, decimals=1))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions\n",
      "pred shape\n",
      "(13999L, 4L)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Make Submission\n",
    "'''\n",
    "\n",
    "#make predictions\n",
    "print('Making predictions')\n",
    "PRED_BATCH = 1\n",
    "def iterate_pred_minibatches(inputs, batchsize):\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt]\n",
    "\n",
    "predictions = []\n",
    "for pred_batch in iterate_pred_minibatches(X_test, PRED_BATCH):\n",
    "    predictions.extend(predict_proba(pred_batch))\n",
    "\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "print('pred shape')\n",
    "print(predictions.shape)\n",
    "\n",
    "with open('submit_NN.csv', 'wb') as mycsvfile:\n",
    "            thedatawriter = csv.writer(mycsvfile)\n",
    "            thedatawriter.writerow(['Id','label'])\n",
    "            for i in range(predictions.shape[0]):\n",
    "                out = [X_test_id[i],predictions[i].argmax(0)+1]\n",
    "                thedatawriter.writerow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes = 4\n",
      "6400\n",
      "6400\n"
     ]
    }
   ],
   "source": [
    "def binarizeY(data):\n",
    "    binarized_data = np.zeros((data.size,4))\n",
    "    for j in range(0,data.size):\n",
    "        feature = data[j:j+1]\n",
    "        i = feature.astype(np.int64) \n",
    "        binarized_data[j,i]=1\n",
    "    return binarized_data\n",
    "train_y_b = binarizeY(train_y)\n",
    "valid_y_b = binarizeY(valid_y)\n",
    "numClasses = train_y_b[1].size\n",
    "print 'Classes = %d' %(numClasses)\n",
    "print len(train_X)\n",
    "print len(train_y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:41: UserWarning: pool_2d() will have the parameter ignore_border default value changed to True (currently False). To have consistent behavior with all Theano version, explicitly add the parameter ignore_border=True. On the GPU, using ignore_border=True is needed to use cuDNN. When using ignore_border=False and not using cuDNN, the only GPU combination supported is when `ds == st and padding == (0, 0) and mode == 'max'`. Otherwise, the convolution will be executed on CPU.\n",
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:42: UserWarning: pool_2d() will have the parameter ignore_border default value changed to True (currently False). To have consistent behavior with all Theano version, explicitly add the parameter ignore_border=True. On the GPU, using ignore_border=True is needed to use cuDNN. When using ignore_border=False and not using cuDNN, the only GPU combination supported is when `ds == st and padding == (0, 0) and mode == 'max'`. Otherwise, the convolution will be executed on CPU.\n",
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:43: UserWarning: pool_2d() will have the parameter ignore_border default value changed to True (currently False). To have consistent behavior with all Theano version, explicitly add the parameter ignore_border=True. On the GPU, using ignore_border=True is needed to use cuDNN. When using ignore_border=False and not using cuDNN, the only GPU combination supported is when `ds == st and padding == (0, 0) and mode == 'max'`. Otherwise, the convolution will be executed on CPU.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1,512) and (1152,600) not aligned: 512 (dim 1) != 1152 (dim 0)\nApply node that caused the error: dot(Elemwise{true_div,no_inplace}.0, <TensorType(float64, matrix)>)\nToposort index: 121\nInputs types: [TensorType(float64, matrix), TensorType(float64, matrix)]\nInputs shapes: [(1L, 512L), (1152L, 600L)]\nInputs strides: [(4096L, 8L), (4800L, 8L)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Elemwise{maximum,no_inplace}(dot.0, DimShuffle{x,x}.0), Elemwise{maximum}(dot.0, DimShuffle{x,x}.0), Elemwise{EQ}(Elemwise{maximum}.0, dot.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"C:\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Anaconda2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-95-e2b030a6dd46>\", line 47, in <module>\n    y_hat_train = model(X, w_1, w_2, w_3, w_4, w_5, 0.2, 0.5)\n  File \"<ipython-input-95-e2b030a6dd46>\", line 44, in model\n    l4 = dropout(T.maximum(T.dot(l3, w_4), 0.), p_2)\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-e2b030a6dd46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'train time = %.2f'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainTime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m \u001b[0mgradientDescentStochastic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-95-e2b030a6dd46>\u001b[0m in \u001b[0;36mgradientDescentStochastic\u001b[1;34m(epochs)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminiBatchSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminiBatchSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminiBatchSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y_b\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[0mtrainTime\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mtrainTime\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[1;34m'%d) accuracy = %.4f'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\theano\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    873\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 875\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    876\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\theano\\theano\\gof\\link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\theano\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\theano\\theano\\gof\\op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    906\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    909\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\theano\\theano\\tensor\\basic.pyc\u001b[0m in \u001b[0;36mperform\u001b[1;34m(self, node, inp, out)\u001b[0m\n\u001b[0;32m   5461\u001b[0m         \u001b[1;31m# gives a numpy float object but we need to return a 0d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5462\u001b[0m         \u001b[1;31m# ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5463\u001b[1;33m         \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5465\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1,512) and (1152,600) not aligned: 512 (dim 1) != 1152 (dim 0)\nApply node that caused the error: dot(Elemwise{true_div,no_inplace}.0, <TensorType(float64, matrix)>)\nToposort index: 121\nInputs types: [TensorType(float64, matrix), TensorType(float64, matrix)]\nInputs shapes: [(1L, 512L), (1152L, 600L)]\nInputs strides: [(4096L, 8L), (4800L, 8L)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Elemwise{maximum,no_inplace}(dot.0, DimShuffle{x,x}.0), Elemwise{maximum}(dot.0, DimShuffle{x,x}.0), Elemwise{EQ}(Elemwise{maximum}.0, dot.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"C:\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Anaconda2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-95-e2b030a6dd46>\", line 47, in <module>\n    y_hat_train = model(X, w_1, w_2, w_3, w_4, w_5, 0.2, 0.5)\n  File \"<ipython-input-95-e2b030a6dd46>\", line 44, in model\n    l4 = dropout(T.maximum(T.dot(l3, w_4), 0.), p_2)\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "from theano.tensor.signal.downsample import max_pool_2d\n",
    "\n",
    "## (1) Parameters\n",
    "numHiddenNodes = 600 \n",
    "patchWidth = 3\n",
    "patchHeight = 3\n",
    "featureMapsLayer1 = 32\n",
    "featureMapsLayer2 = 64\n",
    "featureMapsLayer3 = 128\n",
    "\n",
    "# For convonets, we will work in 2d rather than 1d.  The MNIST images are 28x28 in 2d.\n",
    "#imageWidth = 28\n",
    "#train_data = train_data.reshape(-1, 1, imageWidth, imageWidth)\n",
    "#test_data = test_data.reshape(-1, 1, imageWidth, imageWidth)\n",
    "\n",
    "# Convolution layers.  \n",
    "w_1 = theano.shared(np.asarray((np.random.randn(*(featureMapsLayer1, 1, patchWidth, patchHeight))*.01)))\n",
    "w_2 = theano.shared(np.asarray((np.random.randn(*(featureMapsLayer2, featureMapsLayer1, patchWidth, patchHeight))*.01)))\n",
    "w_3 = theano.shared(np.asarray((np.random.randn(*(featureMapsLayer3, featureMapsLayer2, patchWidth, patchHeight))*.01)))\n",
    "\n",
    "# Fully connected NN. \n",
    "w_4 = theano.shared(np.asarray((np.random.randn(*(featureMapsLayer3 * 3 * 3, numHiddenNodes))*.01)))\n",
    "w_5 = theano.shared(np.asarray((np.random.randn(*(numHiddenNodes, numClasses))*.01)))\n",
    "params = [w_1, w_2, w_3, w_4, w_5]\n",
    "\n",
    "## (2) Model\n",
    "X = T.tensor4() # conv2d works with tensor4 type\n",
    "Y = T.matrix()\n",
    "\n",
    "srng = RandomStreams()\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        X *= srng.binomial(X.shape, p=1 - p)\n",
    "        X /= 1 - p\n",
    "    return X\n",
    "\n",
    "# Theano provides built-in support for add convolutional layers\n",
    "def model(X, w_1, w_2, w_3, w_4, w_5, p_1, p_2):\n",
    "    l1 = dropout(max_pool_2d(T.maximum(conv2d(X, w_1, border_mode='full'),0.), (2, 2)), p_1)\n",
    "    l2 = dropout(max_pool_2d(T.maximum(conv2d(l1, w_2), 0.), (2, 2)), p_1)\n",
    "    l3 = dropout(T.flatten(max_pool_2d(T.maximum(conv2d(l2, w_3), 0.), (2, 2)), outdim=2), p_1) # flatten to switch back to 1d layers\n",
    "    l4 = dropout(T.maximum(T.dot(l3, w_4), 0.), p_2)\n",
    "    return T.nnet.softmax(T.dot(l4, w_5))\n",
    "\n",
    "y_hat_train = model(X, w_1, w_2, w_3, w_4, w_5, 0.2, 0.5)\n",
    "y_hat_predict = model(X, w_1, w_2, w_3, w_4, w_5, 0., 0.)\n",
    "#y_x = T.argmax(y_hat, axis=1)\n",
    "\n",
    "## (3) Cost\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat_train, Y))\n",
    "\n",
    "## (4) Minimization.  \n",
    "def backprop(cost, w, alpha=0.001, rho=0.9, epsilon=1e-6):\n",
    "    grads = T.grad(cost=cost, wrt=w)\n",
    "    updates = []\n",
    "    for w1, grad in zip(w, grads):\n",
    "        \n",
    "        # adding gradient scaling\n",
    "        acc = theano.shared(w1.get_value() * 0.)\n",
    "        acc_new = rho * acc + (1 - rho) * grad ** 2\n",
    "        gradient_scaling = T.sqrt(acc_new + epsilon)\n",
    "        grad = grad / gradient_scaling\n",
    "        updates.append((acc, acc_new))\n",
    "        \n",
    "        updates.append((w1, w1 - grad * alpha))\n",
    "    return updates\n",
    "\n",
    "update = backprop(cost, params)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
    "y_pred = T.argmax(y_hat_predict, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "miniBatchSize = 1\n",
    "def gradientDescentStochastic(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    start_time = time.time()\n",
    "    for i in range(epochs):\n",
    "        for start, end in zip(range(0, len(train_X), miniBatchSize), range(miniBatchSize, len(train_X), miniBatchSize)):\n",
    "            cost = train(train_X[start:end], train_y_b[start:end])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        print '%d) accuracy = %.4f' %(i+1, np.mean(np.argmax(valid_y_b, axis=1) == predict(valid_X)))\n",
    "    print 'train time = %.2f' %(trainTime)\n",
    "\n",
    "gradientDescentStochastic(10)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(valid_X)   \n",
    "print 'predict time = %.2f' %(time.time() - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
